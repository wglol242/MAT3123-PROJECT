# ë‡Œ ì¢…ì–‘ ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ê³¼ ì˜ë£Œ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í™œìš©í•œ <br/>í†µí•© ì§„ë‹¨ ìƒíƒœê³„ êµ¬ì¶•
***2020272037 ì˜ê³µí•™ë¶€ ê¹€ì›ì§„***

>Project idea 12. Medical Image Segmentation
>-------------------------------------------
> 
>Objective:
>
>Develop a model to segment and classify regions in medical images (e.g., MRI, CT scans).
>
>Approach:
>
>Use a medical image dataset (e.g., BraTS for brain tumor segmentation).
>
>Preprocess the images (e.g., normalization, resizing).
>Implement a U-Net or a similar architecture for image segmentation.
>
>Train the model on labeled images to classify and segment regions of interest.
>
>Evaluate segmentation performance using Dice coefficient, IoU, and visual inspection.

## í”„ë¡œì íŠ¸ ì„¤ëª…

![ì œëª© ì—†ëŠ” ë‹¤ì´ì–´ê·¸ë¨ drawio (3)](https://github.com/user-attachments/assets/901f884e-2dcb-4017-b9b3-6f407b783b08)

### ëª©ì 

ì´ í”„ë¡œì íŠ¸ì˜ ëª©í‘œëŠ” U-Net ê¸°ë°˜ ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ë‡Œ ì¢…ì–‘ ë¶€ìœ„ë¥¼ ìë™ìœ¼ë¡œ ì„¸ê·¸ë©˜í…Œì´ì…˜í•˜ê³ , ì´ë¥¼ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ë˜í•œ, í™˜ìê°€ ì§„ë£Œ ì „ì— ì‘ì„±í•œ ì¦ìƒ ë°ì´í„°ë¥¼ í†µí•´ ê´€ë ¨ ì •ë³´ë¥¼ í¬í•¨í•œ ë°ì´í„°ë² ì´ìŠ¤ì™€ ì—°ê³„í•˜ì—¬ ì˜ì‹¬ë˜ëŠ” ë‡Œ ì†ìƒ ë¶€ìœ„ë¥¼ ì˜ˆì¸¡í•˜ê³ , í•™ìŠµëœ ëª¨ë¸ê³¼ì˜ êµì°¨ ê²€ì¦(Cross-check)ì„ í†µí•´ ìµœì¢…ì ìœ¼ë¡œ ì¢…ì–‘ ë¶€ìœ„ë¥¼ í™•ì •í•©ë‹ˆë‹¤.

ì´ëŸ¬í•œ ê³¼ì •ì„ ìˆ˜í–‰í•˜ëŠ” ì´ìœ ëŠ”, ë‡Œ ì¢…ì–‘ì˜ íŠ¹ì„±ìƒ ê°™ì€ ìœ„ì¹˜ì˜ ì¢…ì–‘ì´ë¼ë„ í™˜ìë§ˆë‹¤ ë‹¤ë¥¸ ì¦ìƒê³¼ ì¥ì• ë¥¼ ë³´ì¼ ìˆ˜ ìˆì–´, ë‹¨ìˆœíˆ ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ë§Œìœ¼ë¡œëŠ” ì •í™•í•œ ì§„ë‹¨ì´ ì–´ë µê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

ë§ˆì§€ë§‰ìœ¼ë¡œ, í™•ì •ëœ ì¢…ì–‘ ë¶€ìœ„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë³‘ì› ì •ë³´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í™œìš©í•˜ì—¬ ìµœì ì˜ ë³‘ì›ê³¼ ì˜ì‚¬ ì •ë³´ë¥¼ ì œê³µí•¨ìœ¼ë¡œì¨, í†µí•©ì ì¸ ì§„ë‹¨ ìƒíƒœê³„ë¥¼ êµ¬ì¶•í•˜ëŠ” ê²ƒì„ ìµœì¢… ëª©í‘œë¡œ í•©ë‹ˆë‹¤.


## í”„ë¡œì íŠ¸ í•„ìˆ˜ ê°œë…

< ë”ë³´ê¸° í´ë¦­ ğŸ–±ï¸ >

<details>
<summary>U-Net</summary>

#### 1. U-Net
![image](https://github.com/user-attachments/assets/2b3a9308-19ed-48ca-9c7f-ad903a5ea0f5)

<details>
<summary>ì½”ë“œ ë³´ê¸°</summary>
  
``` python
def unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS, num_classes):
    """
    3D U-Net ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤. 

    ë§¤ê°œë³€ìˆ˜:
    - IMG_HEIGHT: ì…ë ¥ ë³¼ë¥¨ì˜ ë†’ì´
    - IMG_WIDTH: ì…ë ¥ ë³¼ë¥¨ì˜ ë„ˆë¹„
    - IMG_DEPTH: ì…ë ¥ ë³¼ë¥¨ì˜ ê¹Šì´(ìŠ¬ë¼ì´ìŠ¤ ìˆ˜)
    - IMG_CHANNELS: ì…ë ¥ ë°ì´í„°ì˜ ì±„ë„ ìˆ˜ (ì˜ˆ: 3ì±„ë„ì´ë©´ Flair, T1ce, T2)
    - num_classes: ì¶œë ¥ ì„¸ê·¸ë©˜í…Œì´ì…˜ í´ë˜ìŠ¤ ìˆ˜

    ë°˜í™˜ê°’:
    - model: 3D U-Net ëª¨ë¸ ê°ì²´
    """

    # ì…ë ¥ ë ˆì´ì–´
    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS))
    s = inputs

    # **ìˆ˜ì¶• ê²½ë¡œ(Contraction Path, Encoder)**
    # ë¸”ë¡ 1
    c1 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(s)
    c1 = Dropout(0.1)(c1)  # ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ ë“œë¡­ì•„ì›ƒ
    c1 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c1)
    p1 = MaxPooling3D((2, 2, 2))(c1)  # ë‹¤ìš´ìƒ˜í”Œë§(í•´ìƒë„ ì ˆë°˜ ê°ì†Œ)

    # ë¸”ë¡ 2
    c2 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p1)
    c2 = Dropout(0.1)(c2)
    c2 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c2)
    p2 = MaxPooling3D((2, 2, 2))(c2)

    # ë¸”ë¡ 3
    c3 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p2)
    c3 = Dropout(0.2)(c3)
    c3 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c3)
    p3 = MaxPooling3D((2, 2, 2))(c3)

    # ë¸”ë¡ 4
    c4 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p3)
    c4 = Dropout(0.2)(c4)
    c4 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c4)
    p4 = MaxPooling3D(pool_size=(2, 2, 2))(c4)

    # ë³‘ëª© ì§€ì  (ê°€ì¥ ê¹Šì€ ë ˆì´ì–´)
    c5 = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p4)
    c5 = Dropout(0.3)(c5)
    c5 = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c5)

    # **í™•ì¥ ê²½ë¡œ(Expansive Path, Decoder)**
    # ë¸”ë¡ 6
    u6 = Conv3DTranspose(128, (2, 2, 2), strides=(2, 2, 2), padding='same')(c5)  # ì—…ìƒ˜í”Œë§
    u6 = concatenate([u6, c4])  # ìŠ¤í‚µ ì—°ê²°(Skip Connection)
    c6 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u6)
    c6 = Dropout(0.2)(c6)
    c6 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c6)

    # ë¸”ë¡ 7
    u7 = Conv3DTranspose(64, (2, 2, 2), strides=(2, 2, 2), padding='same')(c6)
    u7 = concatenate([u7, c3])
    c7 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u7)
    c7 = Dropout(0.2)(c7)
    c7 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c7)

    # ë¸”ë¡ 8
    u8 = Conv3DTranspose(32, (2, 2, 2), strides=(2, 2, 2), padding='same')(c7)
    u8 = concatenate([u8, c2])
    c8 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u8)
    c8 = Dropout(0.1)(c8)
    c8 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c8)

    # ë¸”ë¡ 9
    u9 = Conv3DTranspose(16, (2, 2, 2), strides=(2, 2, 2), padding='same')(c8)
    u9 = concatenate([u9, c1])
    c9 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u9)
    c9 = Dropout(0.1)(c9)
    c9 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c9)

    # ì¶œë ¥ ë ˆì´ì–´
    outputs = Conv3D(num_classes, (1, 1, 1), activation='softmax')(c9)

    # ëª¨ë¸ ìƒì„±
    model = Model(inputs=[inputs], outputs=[outputs])
    # ëª¨ë¸ êµ¬ì¡° ì¶œë ¥
    model.summary()

    return model
```
</details>

U-Netì€ Biomedical ë¶„ì•¼ì—ì„œ ì´ë¯¸ì§€ ë¶„í• (Image Segmentation)ì„ ëª©ì ìœ¼ë¡œ ì œì•ˆëœ End-to-End ë°©ì‹ì˜ Fully-Convolutional Network ê¸°ë°˜ ëª¨ë¸ì…ë‹ˆë‹¤. 

ëª¨ë¸ì€ ìˆ˜ì¶• ë‹¨ê³„(Contracting Path)ì™€ íŒ½ì°½ ë‹¨ê³„(Expanding Path)ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ì´ëŠ” Coarse Mapì—ì„œ Dense Predictionì„ ì–»ê¸° ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. 

ë˜í•œ, U-Netì€ FCN(Fully Convolutional Network)ì˜ Skip Architecture ê°œë…ì„ í™œìš©í•˜ì—¬ ì–•ì€ ì¸µì˜ íŠ¹ì§•ë§µì„ ê¹Šì€ ì¸µì˜ íŠ¹ì§•ë§µê³¼ ê²°í•©í•˜ëŠ” ë°©ì‹ì„ ì œì•ˆí–ˆìŠµë‹ˆë‹¤. 

ì´ëŸ¬í•œ Feature Hierarchy ê²°í•©ì„ í†µí•´, Segmentationì´ ìš”êµ¬í•˜ëŠ” Localization(ìœ„ì¹˜ ì •ë³´)ê³¼ Context(ì˜ë¯¸ ì •ë³´) ê°„ì˜ íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

***Contracting Path (ìˆ˜ì¶• ë‹¨ê³„)***  
- 3Ã—3 Convolutionì„ ë‘ ì°¨ë¡€ ë°˜ë³µ (íŒ¨ë”© ì—†ìŒ)  
- í™œì„±í™” í•¨ìˆ˜: ReLU  
- 2Ã—2 Max-Pooling (stride: 2)  
- Down-samplingë§ˆë‹¤ ì±„ë„ ìˆ˜ë¥¼ 2ë°°ë¡œ ì¦ê°€  

***Expanding Path (íŒ½ì°½ ë‹¨ê³„)***  
- 2Ã—2 Convolution ("Up-convolution")  
- 3Ã—3 Convolutionì„ ë‘ ì°¨ë¡€ ë°˜ë³µ (íŒ¨ë”© ì—†ìŒ)  
- Up-convolutionë§ˆë‹¤ ì±„ë„ ìˆ˜ë¥¼ ì ˆë°˜ìœ¼ë¡œ ê°ì†Œ  
- í™œì„±í™” í•¨ìˆ˜: ReLU  
- Up-convolutionëœ íŠ¹ì§•ë§µì„ Contracting Pathì˜ Croppedëœ íŠ¹ì§•ë§µê³¼ ì—°ê²°(Concatenation)  
- ë§ˆì§€ë§‰ ë ˆì´ì–´ì—ì„œ 1Ã—1 Convolution ìˆ˜í–‰  

ìœ„ì™€ ê°™ì€ êµ¬ì¡°ë¡œ, U-Netì€ ì´ 23ê°œì˜ Fully Convolutional Layersë¥¼ ê°–ì¶˜ ë„¤íŠ¸ì›Œí¬ë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. 

ì´ëŸ¬í•œ êµ¬ì„±ì€ Localization(ìœ„ì¹˜ ì •ë³´)ì™€ Context(ì˜ë¯¸ ì •ë³´)ë¥¼ ê· í˜• ìˆê²Œ ì²˜ë¦¬í•˜ì—¬ ë†’ì€ ì„±ëŠ¥ì˜ ì´ë¯¸ì§€ ë¶„í•  ê²°ê³¼ë¥¼ ì œê³µí•˜ê¸° ë•Œë¬¸ì— ì´ë²ˆ í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš© ë˜ì—ˆìŠµë‹ˆë‹¤.
</details>

<details>
<summary>Dice ì†ì‹¤ í•¨ìˆ˜</summary>

#### 2. Dice ì†ì‹¤ í•¨ìˆ˜

DICE ì†ì‹¤ í•¨ìˆ˜(Dice Loss)ëŠ” ì£¼ë¡œ ì˜ë£Œ ì˜ìƒ ë¶„ì„ê³¼ ê°™ì€ ë¶„ì•¼ì—ì„œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¬¸ì œì— ë§ì´ ì‚¬ìš©ë©ë‹ˆë‹¤. 

ì´ ì†ì‹¤ í•¨ìˆ˜ëŠ” ì´ì§„ ë¶„ë¥˜ ì‘ì—…ì—ì„œ ë‘ ìƒ˜í”Œ ì§‘í•©ì˜ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ë©°, íŠ¹íˆ ë¶ˆê· í˜•í•œ ë°ì´í„°ì…‹ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.

- DICE ê³„ìˆ˜

  ![image](https://github.com/user-attachments/assets/243c5d91-9e78-4335-9161-d9cddaab58e1)

  ![image](https://github.com/user-attachments/assets/ffbc778b-4799-44d7-8eea-f39da78e14b5)
  
- DICE ì†ì‹¤í•¨ìˆ˜
  
  ![image](https://github.com/user-attachments/assets/47d7ca0c-a710-4203-acfb-21141e9d3298)
  
  DICE ì†ì‹¤ í•¨ìˆ˜ëŠ” 1ì—ì„œ DICE ê³„ìˆ˜ë¥¼ ëº€ ê°’ìœ¼ë¡œ ì •ì˜ë©ë‹ˆë‹¤.
  ì´ëŠ” ê³„ìˆ˜ê°€ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì†ì‹¤ì´ ì‘ì•„ì§€ë©°, ì˜ˆì¸¡ê³¼ ì‹¤ì œ ê°’ ì‚¬ì´ì˜ ìœ ì‚¬ë„ê°€ ë†’ìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

- ê°€ì¤‘ DICE ì†ì‹¤ í•¨ìˆ˜

  ![image](https://github.com/user-attachments/assets/a382ccd5-f486-4d5e-9b85-cb297f0bf087)

  ê°€ì¤‘ DICE ì†ì‹¤ í•¨ìˆ˜ëŠ” class_weightsë¥¼ í†µí•´ í´ë˜ìŠ¤ë³„ ì¤‘ìš”ë„ë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

  ì½”ë“œì—ì„œëŠ” ê°€ì¤‘ DICE ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í–ˆê³  ëª¨ë‘ ë™ì¼í•˜ê²Œ 0.25ë¥¼ ë¶€ì—¬í–ˆìŠµë‹ˆë‹¤.

   ``` python
  
  import segmentation_models_3D as sm
  dice_loss = sm.losses.DiceLoss(class_weights=np.array([wt0, wt1, wt2, wt3]))  
  
  ``` 
</details>

<details>
<summary>Focal ì†ì‹¤ í•¨ìˆ˜</summary>

#### 3. Focal ì†ì‹¤ í•¨ìˆ˜

Focal ì†ì‹¤ í•¨ìˆ˜ëŠ” ë¶ˆê· í˜• ë°ì´í„° ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ ì†ì‹¤ í•¨ìˆ˜ë¡œ, ì–´ë ¤ìš´ ìƒ˜í”Œì— ë” í° ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ì—¬ í•™ìŠµì„ ì§‘ì¤‘ì‹œí‚µë‹ˆë‹¤.

   ``` python
  
  focal_loss = sm.losses.CategoricalFocalLoss()  # Focal ì†ì‹¤ í•¨ìˆ˜
  
  ``` 

</details>

<details>
<summary>ì „ì²´ ì†ì‹¤ í•¨ìˆ˜</summary>

#### 4. ì „ì²´ ì†ì‹¤ í•¨ìˆ˜

Dice Loss: ë¶„í•  ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ì˜ˆì¸¡ ë§ˆìŠ¤í¬ì™€ ì‹¤ì œ ë§ˆìŠ¤í¬ ê°„ì˜ ê²¹ì¹¨ ì •ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.

Focal Loss: í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ì–´ë ¤ìš´ ìƒ˜í”Œì— ë” ì§‘ì¤‘í•˜ë„ë¡ ì„¤ê³„í•©ë‹ˆë‹¤.

ì „ì²´ ì†ì‹¤ í•¨ìˆ˜: ë‘ ì†ì‹¤ì„ í•©ì‚°í•˜ì—¬ ë¶„í•  ì„±ëŠ¥(Localization)ê³¼ í•™ìŠµ ì•ˆì •ì„±(Class Imbalance í•´ê²°)ì„ ë™ì‹œì— ê°œì„ í–ˆìŠµë‹ˆë‹¤.

   ``` python
  
  total_loss = dice_loss + (1 * focal_loss)  # ì „ì²´ ì†ì‹¤ = Dice + Focal
  
  ``` 
</details>

<details>
<summary>ì •í™•ë„ ë° IoU ì§€í‘œ</summary>

#### 5. ì •í™•ë„ ë° IoU ì§€í‘œ
ì •í™•ë„ (Accuracy): ì „ì²´ í”½ì…€ ì¤‘ ì˜¬ë°”ë¥´ê²Œ ì˜ˆì¸¡í•œ ë¹„ìœ¨ì…ë‹ˆë‹¤.

IoU (Intersection over Union): ì˜ˆì¸¡ëœ ì˜ì—­ê³¼ ì‹¤ì œ ì˜ì—­ì˜ ê²¹ì¹¨ ë¹„ìœ¨ì…ë‹ˆë‹¤.


   ``` python
  
  metrics = ['accuracy', sm.metrics.IOUScore(threshold=0.5)]  # ì •í™•ë„ ë° IoU ì§€í‘œ
  
  ```

</details>

## í”„ë¡œì íŠ¸ ì„¤ì¹˜

***- í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬***
1. TensorFlow
2. segmentation-models-3D
3. psycopg

***- í•„ìš”í•œ  ë°ì´í„°ì…‹***

  [BraTS2020 Dataset](https://www.kaggle.com/datasets/awsaf49/brats20-dataset-training-validation)

## í”„ë¡œì íŠ¸ ì‚¬ìš©ë²• 

### ê° íŒŒì¼ì˜ ì—­í• 

***`get_data.py`*** 

ì˜ë£Œ ì´ë¯¸ì§€ ë°ì´í„°ì…‹(MICCAI BraTS 2020)ì„ ì •ê·œí™” í•˜ê³  ìœ ìš©í•œ ë°ì´í„°ë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤.

***`custom_datagen.py`***

ì´ë¯¸ì§€ ë° ë§ˆìŠ¤í¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ë°°ì¹˜(batch) ë‹¨ìœ„ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

***`unet.py`***

3D U-Net ëª¨ë¸ êµ¬ì¡°ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

***`train.py`***

í•™ìŠµ ë°ì´í„°ì™€ ê²€ì¦ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ 3D U-Net ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤.
  ì†ì‹¤ í•¨ìˆ˜ ë° í‰ê°€ì§€í‘œë¥¼ ì„¤ì •í•˜ê³ , í•™ìŠµ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.

***`load.py`***

ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ IoU ê³„ì‚° ë° ì‹œê°í™”ë¥¼ í†µí•´ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.

***`search.py`***

í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ ìˆ˜í–‰í•˜ê³  ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. 

í™˜ì ì •ë³´ì™€ ë‡Œ ì¦ìƒì„ ê¸°ë°˜ìœ¼ë¡œ ë³‘ì› ë°ì´í„°ë¥¼ ì‹œê°í™”í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤.

***`db.py`***

ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° í™˜ì, ë‡Œ ì¦ìƒ, ë³‘ì› ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ëŠ” í•¨ìˆ˜ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.

### ì§„í–‰ ìˆœì„œ

***1. ë°ì´í„° ì¤€ë¹„ ( `get_data.py` )***
  
ì˜ë£Œ ì´ë¯¸ì§€(.nii)ë¥¼ ë¡œë“œí•œ í›„, `MinMaxScaler`ë¥¼ ì‚¬ìš©í•´ 0~1ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤.

ë§ˆìŠ¤í¬ ë°ì´í„°ëŠ” 3D ë³¼ë¥¨ìœ¼ë¡œ, ê° í”½ì…€ì´ íŠ¹ì • í´ë˜ìŠ¤(ì˜ˆ: 0-ë°°ê²½, 1-í™œì„± ì¢…ì–‘ ë“±)ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë¼ë²¨ë§ ì •ë³´ì…ë‹ˆë‹¤. 

ë§ˆìŠ¤í¬ëŠ” ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜ í›„ ìœ íš¨ ë°ì´í„° ë¹„ìœ¨ì´ 1% ì´ìƒì¼ ê²½ìš°ì—ë§Œ ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ë¥¼ `.npy` í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

- ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ ì˜ˆì‹œ

![image](https://github.com/user-attachments/assets/4d667cd7-1098-4cc2-a8be-733d821daac4)


***2. ë°°ì¹˜ ì²˜ë¦¬ ë° í•™ìŠµ***

`imageLoader`ë¥¼ ì‚¬ìš©í•´ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ê³  ë°˜í™˜í•˜ëŠ” ì œë„ˆë ˆì´í„°ë¥¼ ìƒì„±í•œ í›„, Dice Lossì™€ Focal Lossë¥¼ ì¡°í•©í•œ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ê³  Adam ì˜µí‹°ë§ˆì´ì €ì™€ í•™ìŠµë¥ ì„ ì„¤ì •í•©ë‹ˆë‹¤.  ë˜í•œ, í‰ê°€ ì§€í‘œë¡œ accuracyì™€ IoUë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤. 

`unet.py`ì˜ `unet_model`ì„ í™œìš©í•´ 3D U-Net ëª¨ë¸ì„ ìƒì„±í•˜ê³  ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì €, í‰ê°€ ì§€í‘œë¡œ ëª¨ë¸ì„ ì»´íŒŒì¼í•œ ë’¤, `model.fit()`ì„ ì‚¬ìš©í•´ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤. 

ë§ˆì§€ë§‰ìœ¼ë¡œ í•™ìŠµ ì†ì‹¤ê³¼ ì •í™•ë„ë¥¼ ì‹œê°í™”í•˜ê³ , í•™ìŠµëœ ëª¨ë¸ì„ `brats_3d.hdf5` íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

- í•™ìŠµ ì˜ˆì‹œ 

![320](https://github.com/user-attachments/assets/1c151eae-fe10-4b49-8005-7627f4f3df1c)


***3. í•™ìŠµ ëª¨ë¸ ë¡œë“œ ë° í‰ê°€***

`load.py`ëŠ” í•™ìŠµëœ ëª¨ë¸(`brats_3d.hdf5`)ì„ ë¶ˆëŸ¬ì™€ ê²€ì¦ ë°ì´í„° ì œë„ˆë ˆì´í„°ë¥¼ ìƒì„±í•˜ê³ , ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ì™€ ì‹¤ì œ ë§ˆìŠ¤í¬ë¥¼ ë¹„êµí•˜ì—¬ IoUë¥¼ ê³„ì‚°í•´ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. 

***4. í•™ìŠµëœ ëª¨ë¸ì„ í™œìš©í•œ í™˜ì ë°ì´í„° ë¶„ì„ ë° DB í™œìš©***

í•™ìŠµëœ 3D U-Net ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ ì›í•˜ëŠ” ë‡Œ ì´ë¯¸ì§€ë¥¼ ì„¸ê·¸ë¨¼íŠ¸í•˜ê³ , ì´ë¯¸ì§€ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í™˜ìì˜ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. 

ì´í›„, ì‹œê°í™”ëœ ì„¸ê·¸ë¨¼íŠ¸ ê²°ê³¼ì™€ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ëœ í™˜ìì˜ ì¦ìƒì„ ì°¸ì¡°í•˜ì—¬ ë‹¤ë¥¸ ë°ì´í„°ë² ì´ìŠ¤(EX symptom table)ì—ì„œ ì¦ìƒê³¼ ê´€ë ¨ëœ ë‡Œ ë¶€ìœ„ë¥¼ ì¡°íšŒí•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. 

ì´ë¥¼ í†µí•´ ì„¸ê·¸ë¨¼íŠ¸ëœ ì´ë¯¸ì§€ì™€ ì¦ìƒì— ë”°ë¥¸ ì¢…ì–‘ ë¶€ìœ„ë¥¼ í¬ë¡œìŠ¤ ì²´í¬í•˜ì—¬, ìµœì¢…ì ìœ¼ë¡œ í™˜ìì˜ ì¢…ì–‘ê³¼ ê´€ë ¨ëœ ë³‘ì› ì •ë³´ë¥¼ ë³‘ì› ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒí•˜ê³  ì œê³µí•©ë‹ˆë‹¤.

- í™˜ì DB ì˜ˆì‹œ

![image](https://github.com/user-attachments/assets/88824798-50a7-42a1-b8d8-8ed3a3049c69)

## í•™ìŠµ ê²°ê³¼
Batch í¬ê¸°: 2

Epoch ìˆ˜: 100

Learning Rate: 0.0001

(êµ¬ê¸€ ì½”ë©ì„ í™œìš©)

***1. Training and validation loss***

![ë‹¤ìš´ë¡œë“œ](https://github.com/user-attachments/assets/adb3e252-8c23-4bae-8479-d0ff57284466)

ì†ì‹¤ ê°’ì´ ê¾¸ì¤€íˆ ê°ì†Œí•˜ê³  ê³¼ì í•© ì—†ì´ ì•ˆì •ì ì¸ í•™ìŠµì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.

í•˜ì§€ë§Œ ì†ì‹¤ ê°’ì€ ë§¤ìš° í° í¸ì…ë‹ˆë‹¤..

***2. Training and Validation Accuracy***

![ë‹¤ìš´ë¡œë“œ (1)](https://github.com/user-attachments/assets/73bc2d2f-20d7-485c-87ec-d2bd8c1fe9d9)

í•™ìŠµ ì •í™•ë„ì™€ ê²€ì¦ ì •í™•ë„ê°€ ì•½ 99% ì´ìƒì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.

***3. ì‹œê°ì  í‰ê°€ ë° IoU***

![Figure_1](https://github.com/user-attachments/assets/7ceb58ca-fe59-4938-8f72-167344e76340)

IoU 0.8177ë¡œ ë†’ì€ ì •í™•ë„ë¡œ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.
ì‹œê°ì  í‰ê°€ì—ì„œë„ ì‹¤ì œ ë§ˆìŠ¤í¬ì™€ ì˜ˆì¸¡ ê²°ê³¼ê°€ ìœ ì‚¬í•˜ê²Œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.

### ì¢…í•© í‰ê°€

ì½”ë©ì˜ ì‹œê°„ì  í•œê³„ë¡œ ì¸í•´ ì†ì‹¤ ê°’ì´ ë‹¤ì†Œ í° í¸ì´ì§€ë§Œ, ì „ë°˜ì ìœ¼ë¡œ ì•ˆì •ì ì´ê³  ì¢‹ì€ ê²°ê³¼ë¥¼ ë‚˜íƒ€ëƒˆìŠµë‹ˆë‹¤.

## ìµœì¢… ì‹¤í–‰í™”ë©´

***1. í™˜ìì˜ MRI ì´ë¯¸ì§€*** 

![1](https://github.com/user-attachments/assets/2c6631e4-8537-4bd2-ab49-be55996abc23)

***2. ì¢…ì–‘ ë¶€ìœ„ì˜ ì„¸ê·¸ë©˜ë°ì´ì…˜ ë° ë‡Œ ë¶€ìœ„*** 

![2](https://github.com/user-attachments/assets/61c588e3-eec2-42c5-9d1a-65d9aef93777)

***3. í™˜ì ë°ì´í„°ì™€ ì¦ìƒì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì¢…ì–‘ ë¶€ìœ„ ì˜ˆì¸¡***

![3](https://github.com/user-attachments/assets/046bc788-71a4-402d-983a-e0ee8f42cf47)

***4. í¬ë¡œìŠ¤ ì²´í¬ë¥¼ í†µí•œ ìµœì¢… ì¢…ì–‘ ë¶€ìœ„ í™•ì¸ ë° ê´€ë ¨ ë³‘ì› ëª…ë‹¨ ì œê³µ***

![5](https://github.com/user-attachments/assets/d6644679-a612-406d-bf4b-b34c6cc8b1e1)

## ë³´ì™„ì 

ì²˜ìŒì—ëŠ” ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ í†µí•´ ì¢…ì–‘ ë¶€ìœ„ë¥¼ ì¢Œí‘œë¡œ ê°ì§€í•˜ê³  ì†ìƒ ì˜ì—­ì„ ìë™ìœ¼ë¡œ ì•Œë ¤ì£¼ëŠ” ì‹œìŠ¤í…œì„ êµ¬í˜„í•˜ë ¤ í–ˆìœ¼ë‚˜, ê¸°ìˆ ì  í•œê³„ë¡œ ì¸í•´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.

ë”°ë¼ì„œ í˜„ì¬ëŠ” ì‚¬ëŒì´ ì§ì ‘ ì¢…ì–‘ ë¶€ìœ„ë¥¼ í™•ì¸í•˜ê³  ë°ì´í„°ë² ì´ìŠ¤ì— ì…ë ¥í•´ì•¼ í•˜ëŠ” ë¶ˆí¸í•¨ì´ ì¡´ì¬í•©ë‹ˆë‹¤.

ì´ì— ë”°ë¼, ì°¨ê¸°ì—ëŠ” YOLOë‚˜ Faster R-CNNê³¼ ê°™ì€ ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ì´ëŸ¬í•œ í•œê³„ë¥¼ ê·¹ë³µí•  ê³„íšì…ë‹ˆë‹¤.

## ì°¸ê³ ìë£Œ

https://velog.io/@joongwon00/3D-UNET%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-CTMRI-Image-segmentation-3.-%EC%BD%94%EB%93%9C-%EB%8F%8C%EB%A6%AC%EA%B8%B0

https://medium.com/@msmapark2/u-net-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0-u-net-convolutional-networks-for-biomedical-image-segmentation-456d6901b28a

https://bruders.tistory.com/77

https://github.com/bnsreenu/python_for_microscopists

